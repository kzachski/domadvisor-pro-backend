import express from "express";
import cors from "cors";
import dotenv from "dotenv";
import OpenAI from "openai";

dotenv.config();

const app = express();
app.use(cors());
app.use(express.json());

// ================================================================
//  OPENAI CLIENT ‚Äî NOWY SILNIK "RESPONSES" (jak GPTs)
// ================================================================

const client = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

// ================================================================
//  SYSTEM PROMPT ‚Äî TW√ìJ PE≈ÅNY PROMPT DOMADVISOR
//  (NIC TU NIE ZMIENIAJ ‚Äì wklei≈Çe≈õ go poprawnie)
// ================================================================

const systemPrompt = `üìö DOMADVISOR ‚Äì INSTRUKCJA KOMPLETNA
${"=".repeat(60)}
${systemPrompt} 
`;

// ================================================================
//  NOWA FUNKCJA callModel ‚Äî identyczna jak runtime GPTs
// ================================================================

async function callModel(messages) {
  try {
    const response = await client.responses.create({
      model: "gpt-4o",
      input: messages,
      temperature: 0.3,
      max_output_tokens: 12000,   // d≈Çugie odpowiedzi OK
      tools: [
        { type: "web_browsing" }  // <<< browsing dzia≈Ça jak w GPTs
      ]
    });

    return response.output_text;
  } catch (err) {
    console.error("OpenAI ERROR:", err);
    throw new Error("OpenAI request failed");
  }
}

// ================================================================
//  /api/chat ‚Äî DIALOG (teraz jak GPTs)
// ================================================================

app.post("/api/chat", async (req, res) => {
  try {
    const { message, history } = req.body || {};

    if (!message || !message.trim()) {
      return res.status(400).json({ error: "Brak tre≈õci wiadomo≈õci." });
    }

    const messages = [
      { role: "system", content: systemPrompt },
      ...(history || []),
      { role: "user", content: message }
    ];

    const reply = await callModel(messages);

    return res.json({
      success: true,
      reply
    });

  } catch (err) {
    console.error("/api/chat error:", err);
    return res.status(500).json({
      success: false,
      error: "/api/chat ‚Äî b≈ÇƒÖd serwera."
    });
  }
});

// ================================================================
//  /api/report ‚Äî RAPORT PREMIUM (4000‚Äì6000 s≈Ç√≥w)
//  Tworzony JEDNYM wywo≈Çaniem jak w GPTs
// ================================================================

app.post("/api/report", async (req, res) => {
  try {
    const { location, price, area, floor, description } = req.body || {};

    const userInput = `
Lokalizacja: ${location || "brak"}
Cena: ${price || "brak"}
Metra≈º: ${area || "brak"}
Piƒôtro: ${floor || "brak"}

Opis oferty:
${description || "brak"}
`;

    const messages = [
      { role: "system", content: systemPrompt },
      {
        role: "user",
        content: `
Wygeneruj pe≈Çny RAPORT PREMIUM (4000‚Äì6000 s≈Ç√≥w)
zgodnie z pe≈ÇnƒÖ metodologiƒÖ DomAdvisor.

DANE:
${userInput}
        `
      }
    ];

    const report = await callModel(messages);

    return res.json({
      success: true,
      report
    });

  } catch (err) {
    console.error("/api/report error:", err);
    return res.status(500).json({
      success: false,
      error: "/api/report ‚Äî b≈ÇƒÖd serwera."
    });
  }
});

// ================================================================
//  START SERWERA
// ================================================================

const PORT = process.env.PORT || 3000;
app.listen(PORT, () => {
  console.log("üöÄ DomAdvisor GPTs backend dzia≈Ça!");
  console.log("üîë Klucz OpenAI:", process.env.OPENAI_API_KEY ? "OK ‚úì" : "BRAK ‚úó");
  console.log("üåê Port:", PORT);
});
